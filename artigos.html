<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="images/favicon.png">

    <link href="https://fonts.googleapis.com/css?family=Poppins:200,300,400,600,700" rel="stylesheet">
    <link rel="stylesheet" href="lib/icons/css/material-design-iconic-font.min.css">
    <link rel="stylesheet" href="lib/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="lib/animate/animate.css">
    <link rel="stylesheet" href="lib/owlcarousel/owl.carousel.min.css">
    <link class="color-mode" rel="stylesheet" href="css/styles.css">
    <link class="color-change" rel="stylesheet" href="css/blue.css">
    <script src="https://kit.fontawesome.com/bbe98df1ca.js" crossorigin="anonymous"></script>

    <title>Alvaro Leandro</title>
</head>

<body>

    <!--Preloader-->
    <div class="load-wrapp">
        <div class="effect">
            <p>Álvaro Leandro Cavalcante</p>
            <div class="bar"></div>
        </div>
    </div>
    <!--.Preloader-->

    <div class="header mobile">
        <div class="hamburger">
            <span></span>
            <span></span>
            <span></span>
            <span></span>
        </div>
        <h1>Álvaro Leandro Cavalcante</h1>
    </div>
    <div class="all">
        <div class="left-content">
            <div class="left-scroll">
                <div class="img-avata">
                    <img src="images/alvaro3.jpg" alt="avata" class="zoom">
                </div>
                <h4 class="title-port">Álvaro Leandro Cavalcante</h4>
                <ul class="left-nav">
                    <li><a href="index.html"><i class="zmdi zmdi-hc-fw"></i><span>Home</span></a></li>
                    <li><a href="about.html"><i class="zmdi zmdi-hc-fw"></i><span>Sobre</span></a></li>
                    <li><a href="resume.html"><i class="zmdi zmdi-hc-fw"></i><span>Currículo</span></a></li>
                    <li><a href="portfolio.html"><i class="zmdi zmdi-hc-fw"></i><span>Portfólio</span></a></li>
                    <li><a href="artigos.html" class="active"><i class="fas fa-file-alt"></i><span>Artigos científicos</span></a></li>
                    <li><a href="blog.html"><i class="zmdi zmdi-hc-fw"></i><span>Blog</span></a></li>
                    <li><a href="aulas.html"><i class="zmdi zmdi-youtube-play"></i><span>Apresentações</span></a></li>
                     
                </ul>
                <div class="footer-box">
                    <ul class="list-social">
                        <li><a href="#"><i class="zmdi zmdi-hc-fw"></i></i></a></li>
                        <li><a href="https://stackoverflow.com/users/8405704/alvaro-leandro-cavalcante" target="blank"><i class="zmdi zmdi-hc-fw">
                            <i class="zmdi zmdi-stackoverflow"></i></i></i></a></li>
                        <li><a href="https://www.linkedin.com/in/alvaro-leandro/" target="blank"><i class="zmdi zmdi-hc-fw">
                            <i class="zmdi zmdi-linkedin-box"></i></i></a></li>
                        <li><a href="https://github.com/AlvaroCavalcante" target="blank"><i class="zmdi zmdi-hc-fw">
                            <i class="zmdi zmdi-github-box"></i></i></i></a></li>
                        <li><a href="https://www.kaggle.com/alvarole" target="blank"><i class="zmdi zmdi-hc-fw">
                                <i class="fab fa-kaggle"></i></i></i></a></li>
                    </ul>
                    <p class="foo-text">2020 © copyright<br>Todos os direitos reservados.</p>
                </div>
            </div>
        </div>

        <div class="right-content">
            <div class="right-wrap right-page right-resume">
                <div class="container-fruit">
                    <div class="row">
                        <div class="col-12">
                            <div class="title-page">
                                <h1>Artigos publicados</h1>
                                <p>Contribuições acadêmicas</p>
                            </div>
                        </div>
                        <div class="col-12">
                            <div class="m-t-30"></div>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-lg-4 col-md-6 col-sm-6">
                            <article class="card-post">
                                <div class="img-post">
                                    <a href="https://repositorio.unesp.br/handle/11449/243148" target="blank">
                                        <img src="images/arq_completa_dissert.png" alt="img01"/>
                                    </a>
                                </div>
                                <div class="meta-post">
                                    <span>3 Março, 2023</span> - <a href="https://repositorio.unesp.br/handle/11449/243148" target="blank">Repositório Institucional UNESP</a>
                                </div>
                                <div class="content-post">
                                    <h2><a href="https://repositorio.unesp.br/handle/11449/243148" target="blank">Reconhecimento de palavras em língua de sinais baseado em aprendizado profundo e descritores handcrafted de baixo custo</a></h2>
                                    <div>Diversas técnicas de aprendizado profundo e visão computacional têm sido utilizadas nos últimos anos para a criação de sistemas de reconhecimento e tradução de língua de sinais para a língua nativa a partir de vídeos, servindo como uma ferramenta de comunicação para os milhões de deficientes auditivos ao redor do mundo. Ainda assim, inúmeros fatores devem ser considerados para a criação de um sistema como esse, aumentando a complexidade da tarefa. Primeiramente, o treinamento de um modelo de classificação exige uma grande quantidade de dados, o que representa uma dificuldade visto que esta área sofre com a carência de bases de dados em larga escala disponíveis publicamente. Além disso, a fim de evitar a ambiguidade entre as palavras, é preciso considerar o maior número de parâmetros linguísticos possíveis na execução dos gestos que formam os sinais. Na prática, acrescenta-se ainda que o conjunto tecnológico adotado seja condizente com a realidade, evitando sensores custosos, intrusivos ou com baixa mobilidade...</div>
                                </div>
                                <div class="read-post">
                                    <a href="https://repositorio.unesp.br/handle/11449/243148" target="blank">Ler Mais</a>
                                </div>
                            </article>
                        </div>

                        <div class="col-lg-4 col-md-6 col-sm-6">
                            <article class="card-post">
                                <div class="img-post">
                                    <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/1187803/Efficient-sign-language-recognition-system-and-dataset-creation-method-based/10.1117/12.2601018.full?tab=ArticleLinkCited" target="blank">
                                        <img src="images/libras_paper.png" alt="img01"/>
                                    </a>
                                </div>
                                <div class="meta-post">
                                    <span>22 Março, 2021</span> - <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/1187803/Efficient-sign-language-recognition-system-and-dataset-creation-method-based/10.1117/12.2601018.full?tab=ArticleLinkCited" target="blank">International Conference on Digital Image Processing (ICDIP)</a>
                                </div>
                                <div class="content-post">
                                    <h2><a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/1187803/Efficient-sign-language-recognition-system-and-dataset-creation-method-based/10.1117/12.2601018.full?tab=ArticleLinkCited" target="blank">Efficient sign language recognition system and dataset creation method based on deep learning and image processing</a></h2>
                                    <div>New deep-learning architectures are created every year, achieving state-of-the-art results in image recognition and leading to the belief that, in a few years, complex tasks such as sign language translation will be considerably easier, serving as a communication tool for the hearing-impaired community. On the other hand, these algorithms still need a lot of data to be trained and the dataset creation process is expensive, time-consuming, and slow. Thereby, this work aims to investigate techniques of digital image processing and machine learning that can be used to create a sign language dataset effectively. We argue about data acquisition, such as the frames per second rate to capture or subsample the videos, the background type, preprocessing, and data augmentation, using convolutional neural networks and object detection to create an image classifier and comparing the results based on statistical tests. Different datasets were created to test the hypotheses, containing 14 words used daily and recorded by different smartphones in the RGB color system. We achieved... </div>
                                </div>
                                <div class="read-post">
                                    <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/1187803/Efficient-sign-language-recognition-system-and-dataset-creation-method-based/10.1117/12.2601018.full?tab=ArticleLinkCited" target="blank">Ler Mais</a>
                                </div>
                            </article>
                        </div>

                        <div class="col-lg-4 col-md-6 col-sm-6">
                            <article class="card-post">
                                <div class="img-post">
                                    <a href="https://arxiv.org/abs/2103.11241" target="blank">
                                        <img src="images/coffee1.jpg" alt="img01"/>
                                    </a>
                                </div>
                                <div class="meta-post">
                                    <span>20 Março, 2021</span> - <a href="https://arxiv.org/abs/2103.11241" target="blank">Arxiv</a>
                                </div>
                                <div class="content-post">
                                    <h2><a href="https://arxiv.org/abs/2103.11241" target="blank">Artificial intelligence for detection and quantification of rust and leaf miner in coffee crop</a></h2>
                                    <div>Pest and disease control plays a key role in agriculture since the damage caused by these agents are responsible for a huge economic loss every year. Based on this assumption, we create an algorithm capable of detecting rust (Hemileia vastatrix) and leaf miner (Leucoptera coffeella) in coffee leaves (Coffea arabica) and quantify disease severity using a mobile application as a high-level interface for the model inferences. We used different convolutional neural network architectures to create the object detector, besides the OpenCV library, k-means, and three treatments: the RGB and value to quantification, and the AFSoft software, in addition to the analysis of variance, where we compare the three methods. The results show an average precision of 81, 5% in the detection and that there was no significant statistical difference between treatments to quantify the severity of coffee leaves, proposing a computationally less costly method. The application, together with the trained model, can detect the pest and disease over different image conditions and infection stages and also estimate the disease infection stage.</div>
                                </div>
                                <div class="read-post">
                                    <a href="https://arxiv.org/abs/2103.11241" target="blank">Ler Mais</a>
                                </div>
                            </article>
                        </div>
                    </div>

                    <!-- <div class="loading-more m-t-20">
                        <a href="#">Loading more</a>
                    </div> -->
                </div>
                <!-- Line Bg Effect -->
                <div class="line-bg">
                    <div class="line-item"></div>
                    <div class="line-item"></div>
                    <div class="line-item"></div>
                </div>
                <!-- .Line Bg Effect -->
            </div>
        </div>
    </div>

    <script type="text/javascript" src="lib/jquery.min.js"></script>
    <script type="text/javascript" src="lib/owlcarousel/owl.carousel.js"></script>
    <script type="text/javascript" src="lib/bootstrap/js/popper.min.js"></script>
    <script type="text/javascript" src="lib/bootstrap/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="lib/magnific/jquery.magnific-popup.min.js"></script>
    <script type="text/javascript" src="lib/portfolio/js/isotope.pkgd.min.js"></script>
    <script type="text/javascript" src="js/app.js"></script>
</body>

</html>